<script type="text/javascript">
    RED.nodes.registerType('chatgpt',{
        category: 'ChatGPT',
        color: '#10A37F',
        defaults: {
            name: { value: "" },
            API_KEY: { value: "", required: true },
            Organization: { value: "", required: true },
            topic: { value: ""},
            BaseUrl: { value: "https://api.openai.com" }
        },
        inputs:1,
        outputs:1,
        icon: "arrow-in.png",
        label: function() {
            return this.name||"chatgpt";
        },
        oneditprepare: function () {
            const node = this;
            $('#node-input-topic').typedInput({type:"topic", types:[{
                value: "topic",
                options: [
                    { value: "completion", label: "completion"},
                    { value: "edit", label: "edit"},
                    { value: "image", label: "image"},
                    { value: "turbo", label: "turbo"},
                    { value: "gpt4", label: "gpt4"},
                    { value: "__EMPTY__", label: "read from msg.topic"},
                ],
            }]});
        },
    });
</script>

<script type="text/html" data-template-name="chatgpt">
    <div class="form-row">
        <label for="node-input-name"><i class="icon-tag"></i> Name</label>
        <input type="text" id="node-input-name" placeholder="Name">
    </div>
    <div class="form-row">
        <label for="node-input-API_KEY">
            <i class="icon-tag"></i>
            API_KEY
        </label>
        <input type="text" id="node-input-API_KEY" placeholder="OPENAI_API_KEY">
    </div>
    <div class="form-row">
        <label for="node-input-Organization">
            <i class="icon-tag"></i>
            Organization
        </label>
        <input type="text" id="node-input-Organization" placeholder="organization">
    </div>
    <div class="form-row">
        <label for="node-input-topic">
            <i class="icon-tag"></i>
            Topic
        </label>
        <input type="text" id="node-input-topic" />
    </div>
    <div class="form-row">
        <label for="node-input-BaseUrl">
            <i class="icon-tag"></i>
            BaseUrl
        </label>
        <input type="text" id="node-input-BaseUrl" placeholder="https://api.openai.com">
    </div>
</script>

<script type="text/html" data-help-name="chatgpt">

    <h1>Description</h1>
        <p>A Node-RED node that interacts with OpenAI machine learning models to generate text and image outputs like <a href="https://chat.openai.com/chat">ChatGPT</a> and <a href="https://openai.com/product/dall-e-2">DALLÂ·E 2</a>.</p>
    
    <h2>Setup</h2>
        <p>When editing the nodes properties, to get your <code>OPENAI_API_KEY</code> log in to <a href="https://chat.openai.com/chat">ChatGPT</a> then visit <a href="https://platform.openai.com/account/api-keys">https://platform.openai.com/account/api-keys</a> click "+ Create new secret key" then copy and paste the "API key" into the nodes <code>API_KEY</code> property value.</p>
        <p>To get your <code>Organization</code> visit <a href="https://platform.openai.com/account/org-settings">https://platform.openai.com/account/org-settings</a> then copy and paste the "OrganizationID" into the nodes <code>Organization</code> property value.</p>
        <p>If you can't access <a href="https://api.openai.com">https://api.openai.com</a> directly using the default network, you can set up an API proxy (such as Cloudflare WARP), and then set your service's url into the nodes <code>BaseUrl</code> property value.</p>    

    <h3>Inputs</h3>
        <dl class="message-properties">
            <dt>msg.payload
                <span class="property-type">string</span>
            </dt>
            <dd> The prompt to input into the model. </dd>
            
            <dt class="optional">msg.topic
                <span class="property-type">string</span>
            </dt>
            <dd> The topic and node behavior to select.</dd>
            
            <dt class="optional">msg.function
                <span class="property-type">string</span>
            </dt>
            <dd> (GPT-4 only) The function to be used if specified.</dd>
            
            <dt class="optional">msg.function_call
                <span class="property-type">string</span>
            </dt>
            <dd> (GPT-4 only) Whether to call the function automatically or not. Set to 'auto' if functions are present, 'none' if no functions are specified. [Default:`none` if no functions, `auto` if functions are present]</dd>
            </dl>
            
            <dt class="optional">msg.size
                <span class="property-type">string</span>
            </dt>
            <dd> The desired image dimensions.</dd>
            
            <dt class="optional">msg.format
                <span class="property-type">string</span>
            </dt>
            <dd> The desired image output format.</dd>
            
            <dt class="optional">msg.last
                <span class="property-type">string</span>
            </dt>
            <dd> The input to be edited.</dd>
            
            <dt class="optional">msg.suffix
                <span class="property-type">string</span>
            </dt>
            <dd> The suffix that comes after a completion of inserted text.</dd>
            
            <dt class="optional">msg.history
                <span class="property-type">array</span>
            </dt>
            <dd> The conversation history.</dd> 
            
            <dt class="optional">msg.n
                <span class="property-type">number | string</span>
            </dt>
            <dd> The number of responses desired.</dd>
            
            <dt class="optional">msg.temperature
                <span class="property-type">number | string</span>
            </dt>
            <dd> The sampling temperature to use, between <code>0</code> and <code>2</code>. Higher values like <code>0.8</code> will make the output more random, while lower values like <code>0.2</code> will make it more focused and deterministic.</dd>
            
            <dt class="optional">msg.top_p
                <span class="property-type">number | string</span>
            </dt>
            <dd> An alternative to sampling with temperature.</dd>
            
            <dt class="optional">msg.presence_penalty
                <span class="property-type">number | string</span>
            </dt>
            <dd> Number between <code>-2.0</code> and <code>2.0</code>. Positive values penalize new tokens based on whether they appear in the text so far, increasing the model's likelihood to talk about new topics.</dd>
            
            <dt class="optional">msg.frequency_penalty
                <span class="property-type">number | string</span>
            </dt>
            <dd> Number between <code>-2.0</code> and <code>2.0</code>. Positive values penalize new tokens based on their existing frequency in the text so far, decreasing the model's likelihood to repeat the same line verbatim.</dd>
            
            <dt class="optional">msg.max_tokens
                <span class="property-type">number | string</span>
            </dt>
            <dd> The token count of your prompt plus <code>max_tokens</code> cannot exceed the model's context length. Most models have a context length of <code>2048</code> tokens (except for the newest models, which support <code>4096</code>)</dd>
            
            <dt class="optional">msg.echo
                <span class="property-type">boolean</span>
            </dt>
            <dd> Echo back the prompt in addition to the completion when set to <code>true</code>.</dd>
        </dl>
    
    <h3>Outputs</h3>
        <ol class="node-ports">
            <dl class="message-properties">
                <dt>msg.payload <span class="property-type">string</span></dt>
                <dd>The output of the selected model based on the input prompt.</dd>
                
                <dt>msg.full <span class="property-type">object</span></dt>
                <dd>The full response object of the selected model.</dd>
                
                <dt>msg.history <span class="property-type">array</span></dt>
                <dd>The conversation history.</dd>
            </dl>
        </ol>
    
    <h3>Details</h3>
        <p>Select the node's behavior by setting the Topic property value to <code>completion</code>, <code>edit</code>, <code>image</code>, <code>turbo</code>, or <code>gpt4</code>.</p>
        
        <p>Alternatively you can set the Topic to <code>read from msg.topic</code> to set the behavior dynamically with incoming messages.</p>
        
        <p>1. When <code>msg.topic</code> is set to <code>completion</code>:</p>
        <p>Required <code>msg.payload</code> should be a well-written prompt that provides enough information for the model to know what you want and how it should respond. Its success generally depends on the complexity of the task and quality of your prompt. A good rule of thumb is to think about how you would write a word problem for a middle schooler to solve.</p>
        
        <p>2. When <code>msg.topic</code> is set to <code>image</code>:</p>
        <p>Required <code>msg.payload</code> should be a prompt of text description of the desired image.</p>
        <p>Optional <code>msg.size</code> should be a string of the desired image dimensions. [Default:<code>256x256</code>]</p>
        <p>Optional <code>msg.format</code> should be a string of either <code>b64_json</code> or <code>url</code>. [Default:<code>b64_json</code>]</p>
        
        <p>3. When <code>msg.topic</code> is set to <code>edit</code>:</p>
        <p>Required <code>msg.payload</code> should be a prompt of text to use as a starting point for the edit.</p>
        <p>Required <code>msg.last</code> should be a string of text to use as the input to be edited.</p>
        
        <p>4. When <code>msg.topic</code> is set to <code>turbo</code>:</p>
        <p>Required <code>msg.payload</code> should be a well-written prompt.</p>
        <p>Optional <code>msg.history</code> should be an array of objects containing the conversation history. [Default:<code>[]</code>]</p>
        
        <p>5. When <code>msg.topic</code> is set to <code>gpt4</code>:</p>
        <p>Required <code>msg.payload</code> should be a well-written prompt.</p>
        <p>Optional <code>msg.history</code> should be an array of objects containing the conversation history. [Default:<code>[]</code>]</p>
        <p>Optional <code>msg.function</code> should contain the function to be used if specified. This parameter is only applicable when using GPT-4.</p>
        <p>Optional <code>msg.function_call</code> should indicate whether to call the function automatically or not. It should be set to 'auto' if functions are present, and 'none' if no functions are specified. The default value is 'none' if no functions are specified, and 'auto' if functions are present. This parameter is only applicable when using GPT-4.</p>
    
    <h3>Links</h3>
        <ul>
            <li><a href="https://github.com/HaroldPetersInskipp/node-red-contrib-chatgpt">GitHub</a> - this node's GitHub repository.</li>
            <li><a href="https://flows.nodered.org/node/node-red-contrib-custom-chatgpt">NodeRED</a> - this node's page in the flow library.</li>
            <li><a href="https://www.npmjs.com/package/node-red-contrib-custom-chatgpt">NPM</a> - this node's NPM page.</li>
        </ul>
        
 </script>
